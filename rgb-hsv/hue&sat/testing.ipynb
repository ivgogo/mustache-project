{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hue & Saturation for red plastic detection on meat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/RGB_color_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math\n",
    "import cv2\n",
    "import sys\n",
    "from skimage import exposure\n",
    "from PIL import Image\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_1\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_1/plastic/src_Specim-FX17e-076900055547_00.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_1/plastic/src_Specim-FX17e-076900055547_01.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_1/plastic/src_Specim-FX17e-076900055547_02.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_1/plastic/src_Specim-FX17e-076900055547_03.tiff\"\n",
    "\n",
    "# images_3\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_03.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_11.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_21.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_27.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_32.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_37.tiff\"\n",
    "data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_43.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_51.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_54.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_69.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_3/normal/src_Specim-FX17e-076900055547_71.tiff\"\n",
    "\n",
    "# images_4\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_4/plastic/src_Specim-FX17e-076900055547_00.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_4/plastic/src_Specim-FX17e-076900055547_01.tiff\"     # Plastic yes\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_4/plastic/src_Specim-FX17e-076900055547_02.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_4/plastic/src_Specim-FX17e-076900055547_03.tiff\"\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_4/plastic/src_Specim-FX17e-076900055547_04.tiff\"       # plastic YES\n",
    "# data_file_dir = \"/media/ivan/Ivan/jad/images_4/plastic/src_Specim-FX17e-076900055547_05.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 640, 184)\n"
     ]
    }
   ],
   "source": [
    "example_image = []\n",
    "\n",
    "_, example_image = cv2.imreadmulti(\n",
    "    filename=data_file_dir,\n",
    "    mats=example_image,\n",
    "    flags=cv2.IMREAD_UNCHANGED\n",
    ")\n",
    "\n",
    "example_image = np.asarray(example_image)\n",
    "example_image = np.transpose(example_image, (0, 2, 1))\n",
    "print(example_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================= points =========================================\n",
    "\n",
    "point0 = example_image[:, :, 0]\n",
    "point25 = example_image[:, :, 25]\n",
    "point39 = example_image[:, :, 39]\n",
    "point44 = example_image[:, :, 44]\n",
    "point53 = example_image[:, :, 53]\n",
    "point57 = example_image[:, :, 57]\n",
    "point61 = example_image[:, :, 61]\n",
    "point80 = example_image[:, :, 80]\n",
    "point112 = example_image[:, :, 112]\n",
    "point146 = example_image[:, :, 146]\n",
    "point154 = example_image[:, :, 154]\n",
    "point159 = example_image[:, :, 159]\n",
    "\n",
    "points_list = [25,30,39,44,53,57,61,80,112,146,154,159]\n",
    "\n",
    "# ========================================= peaks =========================================\n",
    "\n",
    "'''\n",
    "Points 25 ,44, 80, 154\n",
    "'''\n",
    "\n",
    "peaks = [point25, point44, point80, point154]\n",
    "peaks_sum = sum(peaks)/len(peaks)\n",
    "\n",
    "# ========================================= N1 =========================================\n",
    "\n",
    "slope1 = np.abs((point0-point25)/(0-25)/10)\n",
    "slope2 = np.abs((point25-point39)/(25-39)/10)\n",
    "slope3 = np.abs((point39-point44)/(39-44)/10)\n",
    "slope4 = np.abs((point44-point53)/(44-53)/10)\n",
    "slope5 = np.abs((point53-point57)/(53-57)/10)\n",
    "slope6 = np.abs((point57-point61)/(57-61)*100)\n",
    "slope7 = np.abs((point61-point80)/(61-80)*10)\n",
    "slope8 = np.abs((point80-point112)/(80-112)/10)\n",
    "slope9 = np.abs((point112-point146)/(112-146)/10)\n",
    "slope10 = np.abs((point146-point159)/(146-159)/10)\n",
    "\n",
    "all_slopes_1 = [slope1, slope2, slope3, slope4, slope5, slope6, slope7, slope8, slope9, slope10]\n",
    "\n",
    "# ========================================= N2 =========================================\n",
    "\n",
    "slope2_1 = np.abs((point25-point44)/(25-44))\n",
    "slope2_2 = np.abs((point57-point61)/(57-61)*100)\n",
    "slope2_3 = np.abs((point44-point80)/(44-80))\n",
    "slope2_4 = np.abs((point80-point112)/(80-112))\n",
    "slope2_5 = np.abs((point112-point154)/(112-154))\n",
    "\n",
    "all_slopes_2 = [slope2_1, slope2_2, slope2_3, slope2_4, slope2_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'point1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m green \u001b[38;5;241m=\u001b[39m example_image[:, :, \u001b[38;5;241m53\u001b[39m] \u001b[38;5;66;03m# 57\u001b[39;00m\n\u001b[1;32m      5\u001b[0m blue \u001b[38;5;241m=\u001b[39m example_image[:, :, \u001b[38;5;241m61\u001b[39m]  \u001b[38;5;66;03m# 61\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m saturation \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mminimum\u001b[38;5;241m.\u001b[39mreduce([\u001b[43mpoint1\u001b[49m, point2, point3, point4, pointd])) \u001b[38;5;241m/\u001b[39m (point1 \u001b[38;5;241m+\u001b[39m point2 \u001b[38;5;241m+\u001b[39m point3 \u001b[38;5;241m+\u001b[39m point4 \u001b[38;5;241m+\u001b[39m pointd)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# all points\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# saturation = (3 * np.minimum.reduce([point1, point2, point3, point4, point5, point6, point7, point8, point9, point10, point11, point12])) / (sum(points_list))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# hue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m hue \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marccos((\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m((red\u001b[38;5;241m-\u001b[39mgreen)\u001b[38;5;241m+\u001b[39m(red\u001b[38;5;241m-\u001b[39mblue)))\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mpow\u001b[39m((red\u001b[38;5;241m-\u001b[39mgreen),\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m+\u001b[39m(red\u001b[38;5;241m-\u001b[39mblue)\u001b[38;5;241m*\u001b[39m(red\u001b[38;5;241m-\u001b[39mblue)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'point1' is not defined"
     ]
    }
   ],
   "source": [
    "# valle característico plástico \n",
    "# red = example_image[:, :, 53]   # 53\n",
    "red = example_image[:, :, 57]   # 58\n",
    "green = example_image[:, :, 53] # 57\n",
    "blue = example_image[:, :, 61]  # 61\n",
    "\n",
    "saturation = (3 * np.minimum.reduce([point1, point2, point3, point4, pointd])) / (point1 + point2 + point3 + point4 + pointd)\n",
    "\n",
    "# all points\n",
    "# saturation = (3 * np.minimum.reduce([point1, point2, point3, point4, point5, point6, point7, point8, point9, point10, point11, point12])) / (sum(points_list))\n",
    "\n",
    "# all points + derivative of region 1 of interest plastic\n",
    "# saturation = (3 * np.minimum.reduce([point1, point2, point3, point4, point5, point6, point7, point8, point9, point10, point11, point12, pointd])) / (sum(points_list) + pointd)\n",
    "\n",
    "# hue\n",
    "hue = np.arccos((1/2*((red-green)+(red-blue)))/np.sqrt(pow((red-green),2)+(red-blue)*(red-blue)))\n",
    "\n",
    "# compare element by element\n",
    "condition = np.less_equal(blue, green)\n",
    "\n",
    "# apply condition\n",
    "h = np.where(condition, hue, 360 - hue)\n",
    "print(h.max())\n",
    "final = np.where(h>358.9, 0, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
